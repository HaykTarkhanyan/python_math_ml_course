---
title: "08 Optim: Univariate (GSS, Brent)"
format:
  html:
    css: homework-styles.css
---

<script src="homework-scripts.js"></script>

![image.png](../background_photos/math_08_sevan.jpg)
ÕÖ‡Õ¡Õ¶, [Õ¬Õ¸Ö‚Õ½Õ¡Õ¶Õ¯Õ¡Ö€Õ« Õ°Õ²Õ¸Ö‚Õ´Õ¨](https://unsplash.com/photos/NHXPkAnqmoo), Õ€Õ¥Õ²Õ«Õ¶Õ¡Õ¯Õ [Armen](https://unsplash.com/@armpalanj)


# ğŸ“š Õ†ÕµÕ¸Ö‚Õ©Õ¨

- [ğŸ“š Ô±Õ´Õ¢Õ¸Õ²Õ»Õ¡Õ¯Õ¡Õ¶ Õ¶ÕµÕ¸Ö‚Õ©Õ¨](08_optim_univar.qmd)
- [ğŸ“º ÕÕ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨](https://youtu.be/XFF03oPjAyE)
- [ğŸï¸ ÕÕ¬Õ¡ÕµÕ¤Õ¥Ö€](Lectures/optim/01_univariate.pdf)

ToDo
- [ğŸ› ï¸ğŸ“º Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« Õ¿Õ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨](https://youtu.be/vectors_practical)
- [ğŸ› ï¸ğŸ—‚ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« PDF-Õ¨](Homeworks/hw_01_vectors.pdf)
  

# ğŸ¡ ÕÕ¶Õ¡ÕµÕ«Õ¶

::: {.callout-note collapse="false"}
1. â—â—â— DON'T CHECK THE SOLUTIONS BEFORE TRYING TO DO THE HOMEWORK BY YOURSELFâ—â—â—
2. Please don't hesitate to ask questions, never forget about the ğŸŠkaralyokğŸŠ principle!
3. The harder the problem is, the more ğŸ§€cheesesğŸ§€ it has.
4. Problems with ğŸ are just extra bonuses. It would be good to try to solve them, but also it's not the highest priority task.
5. If the problem involve many boring calculations, feel free to skip them - important part is understanding the concepts.
6. Submit your solutions [here](https://forms.gle/CFEvNqFiTSsDLiFc6) (even if it's unfinished)
:::


## Golden Section Search Implementation ğŸ§€ğŸ§€

::: {.problem}
**Problem 1** ğŸ§€ğŸ§€ Implement Golden Section Search (GSS) in Python.

Given the function $f(x) = x^4 - 3x^3 + 2x$ on the interval $[0, 3]$:

**Starting point:** You have 3 points:
- Left endpoint: $a$
- Right endpoint: $b$  
- Current guess: $x_c$ (initially, could be the midpoint)

**In each iteration:** Generate **one new guess** $x_{\text{new}}$ and evaluate $f(x_{\text{new}})$. Compare with $f(x_c)$ to decide which sub-interval to keep. 

### Part (a): Random vs Golden Ratio Selection

a) Implement GSS with **random guess selection**: Generate the new guess $x_{\text{new}}$ randomly within the current interval $[a, b]$ using `np.random.uniform(a, b)`.

b) Implement GSS with **golden ratio** ($\phi = \frac{1 + \sqrt{5}}{2}$): Generate the new guess $x_{\text{new}}$ using the golden ratio formula. 

c) Compare both methods:
   - Run each method with `max_iter=50`
   - Plot the convergence: iteration number vs. interval length
   - Plot the iteration number vs distance to true minimum

### Part (b): Maximum Iterations for Tolerance

For Golden Section Search on interval $[a, b]$.

d) Derive the formula for the number of iterations $n$ needed to reduce the interval to length $\epsilon$.


e) Given $[a, b] = [0, 10]$ and tolerance $\epsilon = 10^{-6}$, how many iterations are required?

f) Implement a function `max_iterations_for_tolerance(a, b, epsilon)` that returns the required number of iterations.

g) Verify your formula by running GSS and checking when the interval length first becomes $< \epsilon$.

### Part (c): Early Stopping Criteria

Add both **absolute** and **relative** stopping criteria to your Golden Section Search implementation:

**Absolute criterion:** Stop if $|f(x^{(k+1)}) - f(x^{(k)})| < \varepsilon_{\text{abs}}$

**Relative criterion:** Stop if $\frac{|f(x^{(k+1)}) - f(x^{(k)})|}{|f(x^{(k)})| + \delta} < \varepsilon_{\text{rel}}$

where $\delta = 10^{-10}$ is a small constant to avoid division by zero.

h) Implement `golden_section_search_with_stopping(f, a, b, max_iter, eps_abs, eps_rel)`

i) Test on $f(x) = (x-2)^2 + 0.001$ on $[0, 4]$ with:
   - `eps_abs = 1e-6`
   - `eps_rel = 1e-4`
   - `max_iter = 100`

j) Report which stopping criterion was triggered and at which iteration.


:::

## Brent's Method with Parabolic Interpolation ğŸ§€ğŸ§€ğŸ§€

::: {.problem}
**Problem 2** ğŸ§€ğŸ§€ğŸ§€ Implement Brent's method using parabolic interpolation.

**Key idea:** Fit a parabola through three points and find its minimum.

Given three points $(x_1, f_1)$, $(x_2, f_2)$, $(x_3, f_3)$, we want to fit $p(x) = ax^2 + bx + c$.

a) Set up the system of linear equations (SLE):
$$\begin{bmatrix} x_1^2 & x_1 & 1 \\ x_2^2 & x_2 & 1 \\ x_3^2 & x_3 & 1 \end{bmatrix} \begin{bmatrix} a \\ b \\ c \end{bmatrix} = \begin{bmatrix} f_1 \\ f_2 \\ f_3 \end{bmatrix}$$

b) Solve using `scipy.linalg.solve` to get coefficients $[a, b, c]$.

d) Implement a simplified Brent's method:
   - Start with three points from the bracket $[a, b]$
   - Try parabolic interpolation
   - If it fails or gives invalid result, use Golden Section Search
   - Repeat until convergence

e) Test on $f(x) = x^4 - 3x^3 + 2$ on $[0, 3]$ and compare convergence with pure GSS.

:::


# ğŸ› ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶
- [ğŸ› ï¸ğŸ“º Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« Õ¿Õ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨]()
- [ğŸ› ï¸ğŸ—‚ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« PDF-Õ¨]()

# ğŸ² 44 (08)
- â–¶ï¸[True size of countries](https://thetruesize.com/)
- ğŸ”—[Random link](https://www.facebook.com/share/r/1ADqbDFGR4/)
- ğŸ‡¦ğŸ‡²ğŸ¶[Rosen Tal (ÔºÕ¡Õ´Õ¡Õ¶Õ¡Õ¯Õ¶ Õ§)](https://www.youtube.com/watch?v=ngcI8vx64f0)
- ğŸŒğŸ¶[Alt-J (Last Year)](https://www.youtube.com/watch?v=-OjkHRp2ti0)
- ğŸ¤Œ[Ô¿Õ¡Ö€Õ£Õ«Õ¶ ToDo]()

<a href="http://s01.flagcounter.com/more/1oO"><img src="https://s01.flagcounter.com/count2/1oO/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter"></a>