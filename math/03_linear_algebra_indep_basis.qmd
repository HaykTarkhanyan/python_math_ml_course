---
title: "03 Linear Independence, Basis, and Systems"
format:
  html:
    css: homework-styles.css
---

<script src="homework-scripts.js"></script>

<!-- 
[image.png](../background_photos/)
[Õ¬Õ¸Ö‚Õ½5. Verify the rank-nullity theorem: $\dim(\text{domain}) = \text{rank}(T) + \dim(\text{kernel}(T))$.



# ğŸ› ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ¶Õ¯Õ¡Ö€Õ« Õ°Õ²Õ¸Ö‚Õ´Õ¨](https://unsplash.com/photos/a-tall-building-with-lots-of-windows-and-balconies-AowELlZmpZM), Õ€Õ¥Õ²Õ«Õ¶Õ¡Õ¯Õ [Gor Davtyan](https://unsplash.com/@gor918) -->

[image.png](../background_photos/math_03_gazananoc.jpg)
[Õ¬Õ¸Ö‚Õ½Õ¡Õ¶Õ¯Õ¡Ö€Õ« Õ°Õ²Õ¸Ö‚Õ´Õ¨](https://unsplash.com/photos/a-close-up-of-a-monkey-in-a-cage-mQF2vmyV0Zc), Ô³Õ¡Õ¦Õ¡Õ¶Õ¡Õ¶Õ¸Ö, Õ€Õ¥Õ²Õ«Õ¶Õ¡Õ¯Õ [Elmira Gokoryan](https://unsplash.com/@elmira)

      

# ğŸ“š Õ†ÕµÕ¸Ö‚Õ©Õ¨ ToDo

- [ğŸ“š Ô±Õ´Õ¢Õ¸Õ²Õ»Õ¡Õ¯Õ¡Õ¶ Õ¶ÕµÕ¸Ö‚Õ©Õ¨]()
- [ğŸ“º ÕÕ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨]()
- [ğŸï¸ ÕÕ¬Õ¡ÕµÕ¤Õ¥Ö€ - ToDo](Lectures/L01_Vectors.pdf)
- [ğŸï¸ ÕÕ¬Õ¡ÕµÕ¤Õ¥Ö€ - Geometry](Lectures/L02_Geometry_of_Vectors__Matrices.pdf)
- [ğŸ› ï¸ğŸ“º Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« Õ¿Õ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨](https://youtu.be/vectors_practical)
- [ğŸ› ï¸ğŸ—‚ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« PDF-Õ¨](Homeworks/hw_01_vectors.pdf)
  


# ğŸ¡ ÕÕ¶Õ¡ÕµÕ«Õ¶

::: {.callout-note collapse="false"}
1. â—â—â— DON'T CHECK THE SOLUTIONS BEFORE TRYING TO DO THE HOMEWORK BY YOURSELFâ—â—â—
2. Please don't hesitate to ask questions, never forget about the ğŸŠkaralyokğŸŠ principle!
3. The harder the problem is, the more ğŸ§€cheesesğŸ§€ it has.
4. Problems with ğŸ are just extra bonuses. It would be good to try to solve them, but also it's not the highest priority task.
5. If the problem involve many boring calculations, feel free to skip them - important part is understanding the concepts.
6. Submit your solutions [here](https://forms.gle/CFEvNqFiTSsDLiFc6) (even if it's unfinished)
:::


## Systems of Linear Equations

### 01: GPS positioning - from 2D to 3D {data-difficulty="2"}

::: {.callout-note collapse="true" appearance="minimal"}
#### Context
GPS systems solve systems of equations to determine location. Understanding this process helps grasp how linear systems work in practice and why we need the right number of equations.
:::

**Part A: 2D Positioning (Easier warm-up)**

Imagine you're lost in a 2D world and receive distance signals from cell towers:
- Tower A at (0, 0): You are 5 units away
- Tower B at (6, 0): You are 3 units away

1. Write the system of equations for your position (x, y).
2. Solve it step by step using substitution or elimination.
3. Plot the circles and find their intersection point(s).

**Part B: 3D GPS Challenge**

Now for real GPS with 4 satellites in 3D space:
- Why do you need exactly 4 satellites for 3D positioning when you only need 2 towers for 2D?
- What happens if you only have 3 satellites? 
- What happens if you have 5 satellites and they give slightly different measurements?

### 02: Linear regression with normal equations {data-difficulty="2"}

::: {.callout-note collapse="true" appearance="minimal"}
#### Context
The normal equation provides a direct way to solve linear regression problems, connecting linear algebra to machine learning prediction tasks.
:::

You have the following data points for house size (x) vs price (y):
- (50, 100), (100, 180), (150, 280)

1. Set up the design matrix X (including the intercept column) and target vector y.
2. Solve the normal equation $\vec{\theta} = (X^T X)^{-1} X^T \vec{y}$ using Gaussian elimination.
3. Find the line equation $y = \theta_0 + \theta_1 x$.
4. Plot the data points and your fitted line.
5. Predict the price for a 120 square meter house.

### 03: The cheese shop multicollinearity problem {data-difficulty="2"}

::: {.callout-note collapse="true" appearance="minimal"}
#### Context
Real datasets often contain redundant features that are linear combinations of each other, causing problems in machine learning models.
:::

A cheese shop tracks the following features for each cheese:
- Price in AMD: $p_1$
- Price in USD: $p_2$ 
- Weight in kilograms: $w_1$
- Weight in pounds: $w_2$

Given the conversion rates: 1 USD = 400 AMD and 1 kg = 2.2 pounds.

1. **Linear dependence detection**: Which features are linearly dependent? Write the exact relationships.

2. **Matrix rank problem**: If you create a data matrix with these 4 features for 100 cheeses, what would be the maximum possible rank? Why?

3. **Feature selection**: Which 2 features should you keep to avoid multicollinearity? Explain your choice.

4. **System solvability**: If you try to fit a model using all 4 features, what problems might arise?

### 04: The image compression rank revelation {data-difficulty="3"}

::: {.callout-note collapse="true" appearance="minimal"}
#### Context
Understanding matrix rank helps explain how image compression works and why we can store images more efficiently without losing much visual quality.
:::

Consider a grayscale image represented as a matrix:
$$A = \begin{pmatrix} 100 & 150 & 200 \\ 200 & 300 & 400 \\ 50 & 75 & 100 \end{pmatrix}$$

1. **Rank analysis**: Calculate the rank of this image matrix. What does this tell you about the image structure?

2. **Compression potential**: If this represents a 3Ã—3 pixel image, how many numbers do you actually need to store it losslessly? 

3. **Real-world connection**: Why do most natural images have much lower rank than their dimensions suggest? What does this mean for compression algorithms like JPEG?

4. **The storage paradox**: A 1000Ã—1000 image should need 1,000,000 numbers, but often can be compressed to 50,000 numbers with minimal quality loss. How does rank theory explain this?

### 05: The social network influence model {data-difficulty="2"}

::: {.callout-note collapse="true" appearance="minimal"}
#### Context
Social networks can be modeled using linear systems where influence flows between users, helping understand how information spreads and how to detect influential users.
:::

In a small social network, user influence follows these relationships:
- Alice's influence = 0.5 Ã— Bob's influence + 0.3 Ã— Carol's influence + 2
- Bob's influence = 0.4 Ã— Alice's influence + 0.2 Ã— Carol's influence + 1  
- Carol's influence = 0.1 Ã— Alice's influence + 0.6 Ã— Bob's influence + 3

1. **System setup**: Write this as a matrix equation $A\vec{x} = \vec{b}$ where $\vec{x}$ represents the influence scores.

2. **Solution method**: Solve using Gaussian elimination to find each person's influence score.

3. **Stability analysis**: What happens if we change the external influence factors (the constants 2, 1, 3)? Does the system always have a unique solution?

4. **Network insights**: Who is the most influential person in this network? How do the coefficients relate to the network structure?



# ğŸ› ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶
- [ğŸ› ï¸ğŸ“º Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« Õ¿Õ¥Õ½Õ¡Õ£Ö€Õ¸Ö‚Õ©ÕµÕ¸Ö‚Õ¶Õ¨]()
- [ğŸ› ï¸ğŸ—‚ï¸ Ô³Õ¸Ö€Õ®Õ¶Õ¡Õ¯Õ¡Õ¶Õ« PDF-Õ¨]()

# ğŸ² 40 (03)
- â–¶ï¸[]()
- ğŸ”—[Random link](https://www.youtube.com/watch?v=qTkpyUHBGDA)
- ğŸ‡¦ğŸ‡²ğŸ¶[]()
- ğŸŒğŸ¶[Chet Baker (Almost blue)](https://www.youtube.com/watch?v=z4PKzz81m5c)
- ğŸ¤Œ[Ô¿Õ¡Ö€Õ£Õ«Õ¶]()