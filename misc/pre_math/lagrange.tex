% Constrained Optimization: Lagrange Multipliers and KKT (Beamer Presentation)
\documentclass[aspectratio=169]{beamer}
\usepackage{amsmath, amssymb, graphicx, tikz, pgfplots}
\pgfplotsset{compat=1.18}

\usetheme{Madrid}
\usecolortheme{default}

\title{Optimization with Lagrange Multipliers}
\subtitle{Unconstrained basics + Equality and Inequality Constraints (KKT)}
\author{}
\date{}

\newcommand{\R}{\mathbb{R}}
\newcommand{\grad}{\nabla}

\begin{document}

\frame{\titlepage}

\begin{frame}{Plan}
\begin{enumerate}
\item \textbf{Unconstrained Optimization}: gradients, Hessians, minima
\item \textbf{Equality Constraints}: Lagrange multipliers and intuition
\item \textbf{Inequality Constraints}: KKT conditions and active constraints
\item \textbf{Worked Minimization Examples}: step-by-step solutions
\end{enumerate}
\end{frame}

\begin{frame}{Learning Objectives}
By the end, you should be able to:
\begin{itemize}
\item State and use first- and second-order optimality conditions (unconstrained)
\item Form and solve the \emph{Lagrangian} for equality-constrained problems
\item State KKT conditions for inequality constraints and interpret them
\item Solve standard minimization problems (including checking feasibility and activity)
\end{itemize}
\end{frame}

\section{Unconstrained Optimization}

\begin{frame}{Optimization Problem (Unconstrained)}
\textbf{Goal:}
\[
\min_{x \in \R^n} f(x)
\]
\textbf{Definitions:}
\begin{itemize}
\item \textbf{Objective function} $f:\R^n\to\R$: what we want to minimize.
\item \textbf{Global minimizer} $x^\star$: $f(x^\star) \le f(x)$ for all $x$.
\item \textbf{Local minimizer} $x^\star$: $f(x^\star) \le f(x)$ for all $x$ near $x^\star$.
\end{itemize}
\end{frame}

\begin{frame}{Gradient and Stationary Points}
Assume $f$ is differentiable.

\textbf{Gradient:}
\[
\grad f(x) = \begin{bmatrix}\partial f/\partial x_1\\ \vdots \\ \partial f/\partial x_n\end{bmatrix}
\]

\textbf{First-order necessary condition (FONC):}
If $x^\star$ is a local minimizer (and $f$ is differentiable), then
\[
\grad f(x^\star) = 0.
\]

\textbf{Stationary point:} any $x$ with $\grad f(x)=0$.
\end{frame}

\begin{frame}{Hessian and Second-Order Conditions}
If $f$ is twice differentiable, the \textbf{Hessian} is
\[
\nabla^2 f(x) = \left[\frac{\partial^2 f}{\partial x_i\, \partial x_j}\right]_{i,j=1}^n.
\]

\textbf{Second-order test (common version):}
\begin{itemize}
\item If $\grad f(x^\star)=0$ and $\nabla^2 f(x^\star) \succ 0$ (positive definite), then $x^\star$ is a \emph{strict local minimizer}.
\item If $\nabla^2 f(x^\star) \prec 0$, then $x^\star$ is a local maximizer.
\item If $\nabla^2 f(x^\star)$ is indefinite, then $x^\star$ is a saddle point.
\end{itemize}
\end{frame}

\begin{frame}{Example (Unconstrained Minimization)}
\textbf{Problem:}
\[
\min_{(x,y)\in\R^2} f(x,y) = (x-1)^2 + (y+2)^2.
\]

\textbf{Step 1: Compute the gradient}
\[
\grad f(x,y) = \begin{bmatrix}2(x-1)\\2(y+2)\end{bmatrix}.
\]

\textbf{Step 2: Set $\grad f=0$}
\[
2(x-1)=0 \Rightarrow x=1,\qquad 2(y+2)=0 \Rightarrow y=-2.
\]

\textbf{Conclusion:} Unique minimizer is $(1,-2)$ with minimum value $f(1,-2)=0$.
\end{frame}

\section{Equality Constraints: Lagrange Multipliers}

\begin{frame}{Equality-Constrained Optimization}
\textbf{Problem:}
\[
\min_{x\in\R^n} f(x) \quad \text{s.t.} \quad h(x)=0,
\]
where $h:\R^n\to\R^m$ is differentiable.

\textbf{Feasible set:}
\[
\mathcal{F} = \{x\in\R^n : h(x)=0\}.
\]

\textbf{Interpretation:} We optimize $f$ but we are only allowed to move along the constraint surface $h(x)=0$.
\end{frame}

\begin{frame}{Lagrangian and Lagrange Multipliers}
\textbf{Lagrangian:}
\[
\mathcal{L}(x,\lambda) = f(x) + \lambda^\top h(x),
\]
where $\lambda\in\R^m$ are \textbf{Lagrange multipliers}.

\textbf{Lagrange conditions (first-order, equality case):}
\[
\grad_x \mathcal{L}(x^\star,\lambda^\star) = \grad f(x^\star) + J_h(x^\star)^\top\lambda^\star = 0,
\]
\[
h(x^\star)=0.
\]

Here $J_h(x)$ is the Jacobian matrix of $h$.
\end{frame}

\begin{frame}{Geometric Intuition (Equality Constraints)}
For a single equality constraint $h(x)=0$ in $\R^n$:

\begin{itemize}
\item The feasible directions at $x$ lie in the tangent space to the constraint surface.
\item $\grad h(x)$ is perpendicular (normal) to the constraint surface.
\item At an optimum, the component of $\grad f(x)$ along feasible directions must be zero.
\end{itemize}

\textbf{Key idea:}
\[
\grad f(x^\star) = -\lambda^\star \grad h(x^\star)
\]
So $\grad f$ must be parallel to $\grad h$ (in the 1-constraint case).
\end{frame}

\begin{frame}{Worked Example (Equality Constraint)}
\textbf{Problem:}
\[
\min_{x,y\in\R} \; x^2 + y^2 \quad \text{s.t.} \quad x+y=1.
\]

\textbf{Step 1: Build the Lagrangian}
\[
\mathcal{L}(x,y,\lambda) = x^2 + y^2 + \lambda(x+y-1).
\]

\textbf{Step 2: Stationarity}
\[
\frac{\partial \mathcal{L}}{\partial x} = 2x + \lambda = 0,\qquad
\frac{\partial \mathcal{L}}{\partial y} = 2y + \lambda = 0.
\]
\end{frame}

\begin{frame}{Worked Example (Equality Constraint) --- continued}
From stationarity:
\[
2x+\lambda=0,\; 2y+\lambda=0 \Rightarrow x=y.
\]

\textbf{Step 3: Enforce feasibility}
\[
x+y=1 \Rightarrow 2x=1 \Rightarrow x=\frac12,\; y=\frac12.
\]

\textbf{Step 4: Value at optimum}
\[
f\left(\tfrac12,\tfrac12\right) = \left(\tfrac12\right)^2 + \left(\tfrac12\right)^2 = \tfrac12.
\]

\textbf{Conclusion:} Minimizer is $(x^\star,y^\star)=(\tfrac12,\tfrac12)$.
\end{frame}

\begin{frame}{Multiplier Interpretation (Sensitivity)}
Consider equality constraint $h(x)=b$.

Under regularity conditions, the optimal multiplier $\lambda^\star$ approximates how the optimal value changes when we slightly change $b$:
\[
\frac{d}{db}\, f^\star(b) \approx -\lambda^\star.
\]

\textbf{Meaning:}
\begin{itemize}
\item Large $|\lambda^\star|$: the constraint is ``expensive'' (tight/important).
\item Small $|\lambda^\star|$: the constraint has little effect near optimum.
\end{itemize}
\end{frame}

\section{Inequality Constraints: KKT}

\begin{frame}{Inequality-Constrained Optimization}
We often solve
\[
\min_{x\in\R^n} f(x) \quad \text{s.t.}\quad g_i(x) \le 0\;(i=1,\dots,m),\quad h_j(x)=0\;(j=1,\dots,p).
\]

\textbf{New concepts:}
\begin{itemize}
\item \textbf{Active constraint}: $g_i(x^\star)=0$ (tight/binding).
\item \textbf{Inactive constraint}: $g_i(x^\star)<0$ (slack).
\end{itemize}
\end{frame}

\begin{frame}{KKT: The Lagrangian for Inequalities}
Define the Lagrangian
\[
\mathcal{L}(x,\lambda,\nu) = f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{j=1}^p \nu_j h_j(x),
\]
with multipliers
\[
\lambda_i \ge 0 \; (\text{for inequalities}),\qquad \nu_j\in\R \; (\text{for equalities}).
\]
\end{frame}

\begin{frame}{KKT Conditions (Statement)}
Under suitable regularity conditions (constraint qualifications), a local optimum $x^\star$ satisfies:

\textbf{1) Primal feasibility}
\[
g_i(x^\star) \le 0,\quad h_j(x^\star)=0.
\]

\textbf{2) Dual feasibility}
\[
\lambda_i^\star \ge 0 \quad \forall i.
\]

\textbf{3) Complementary slackness}
\[
\lambda_i^\star\, g_i(x^\star)=0 \quad \forall i.
\]

\textbf{4) Stationarity}
\[
\grad f(x^\star) + \sum_{i=1}^m \lambda_i^\star\, \grad g_i(x^\star) + \sum_{j=1}^p \nu_j^\star\, \grad h_j(x^\star) = 0.
\]
\end{frame}

\begin{frame}{Complementary Slackness (What it Means)}
For each inequality constraint $g_i(x)\le 0$:

\begin{itemize}
\item If the constraint is \textbf{inactive} ($g_i(x^\star)<0$), then complementary slackness forces $\lambda_i^\star=0$.
\item If the constraint is \textbf{active} ($g_i(x^\star)=0$), then $\lambda_i^\star$ may be positive.
\end{itemize}

\textbf{Interpretation:} Only the constraints that are tight at the optimum influence the stationarity equation.
\end{frame}

\begin{frame}{When Are KKT Conditions Also Sufficient?}
KKT conditions are \emph{necessary} for many problems.

They are also \emph{sufficient} for global optimality in the important \textbf{convex} case:
\begin{itemize}
\item $f$ is convex
\item each $g_i$ is convex
\item each $h_j$ is affine (linear + constant)
\item a regularity condition holds (e.g. Slater's condition)
\end{itemize}

Then any point satisfying KKT is a \textbf{global minimizer}.
\end{frame}

\begin{frame}{Worked Example (Inequality, Active Constraint)}
\textbf{Problem:}
\[
\min_{x\in\R} \; x^2 \quad \text{s.t.} \quad x \ge 1.
\]
Rewrite as $g(x) \le 0$ with
\[
g(x) = 1-x \le 0.
\]

\textbf{Lagrangian:}
\[
\mathcal{L}(x,\lambda) = x^2 + \lambda(1-x),\quad \lambda\ge 0.
\]

\textbf{Stationarity:} $\frac{d\mathcal{L}}{dx}=2x-\lambda=0 \Rightarrow \lambda=2x$.
\end{frame}

\begin{frame}{Worked Example (Inequality, Active Constraint) --- continued}
\textbf{Primal feasibility:} $x\ge 1$.

\textbf{Complementary slackness:} $\lambda(1-x)=0$.

Case analysis:
\begin{itemize}
\item If $x>1$ then $1-x<0$ so complementary slackness forces $\lambda=0$, but then stationarity gives $2x=0$ (impossible).
\item Therefore the constraint must be \textbf{active}: $x=1$.
\end{itemize}

Then stationarity gives $\lambda = 2x = 2 \ge 0$ (dual feasible).

\textbf{Conclusion:} Minimizer is $x^\star=1$ with value $f(x^\star)=1$.
\end{frame}

\begin{frame}{Worked Example (Inequality, Inactive Constraint)}
\textbf{Problem:}
\[
\min_{x\in\R} \; (x-2)^2 \quad \text{s.t.} \quad x \ge 0.
\]
Rewrite $g(x)= -x \le 0$.

\textbf{Unconstrained minimizer:} $x=2$.

Check feasibility: $2\ge 0$ so the constraint is \textbf{inactive} at the solution.

KKT perspective:
\begin{itemize}
\item Since $g(2)=-2<0$, complementary slackness forces $\lambda^\star=0$.
\item Stationarity becomes derivative of $f$ equals zero at $x=2$.
\end{itemize}

\textbf{Conclusion:} Minimizer remains $x^\star=2$.
\end{frame}

\begin{frame}{Worked Example (2D Inequalities): Geometry First}
\textbf{Problem:}
\[
\min_{x,y\in\R} \; x^2+y^2 \quad \text{s.t.}\quad x\ge 1,\; y\ge 2.
\]

\textbf{Interpretation:}
\begin{itemize}
\item $x^2+y^2$ is the squared distance from $(x,y)$ to the origin.
\item The feasible set is the quadrant \emph{shifted away} from the origin: $\{(x,y): x\ge 1, y\ge 2\}$.
\item The closest feasible point to the origin is the corner $(1,2)$.
\end{itemize}

So we already expect the minimizer to be $(1,2)$, and both constraints to be \textbf{active}.
\end{frame}

\begin{frame}{Worked Example (2D Inequalities): KKT Setup}
Write constraints as $g_1(x,y)=1-x\le 0$ and $g_2(x,y)=2-y\le 0$.

\textbf{Lagrangian:}
\[
\mathcal{L}(x,y,\lambda_1,\lambda_2)=x^2+y^2+\lambda_1(1-x)+\lambda_2(2-y),\quad \lambda_1,\lambda_2\ge 0.
\]

\textbf{Stationarity:}
\[
\frac{\partial \mathcal{L}}{\partial x}=2x-\lambda_1=0,\qquad
\frac{\partial \mathcal{L}}{\partial y}=2y-\lambda_2=0.
\]

\textbf{Complementary slackness:}
\[
\lambda_1(1-x)=0,\qquad \lambda_2(2-y)=0.
\]
\end{frame}

\begin{frame}{Worked Example (2D Inequalities): Solve + Explain}
Unconstrained minimizer is $(0,0)$, but it is infeasible.

\textbf{Key KKT insight:} If $x>1$ then $(1-x)<0$ so complementary slackness forces $\lambda_1=0$, and stationarity would give $2x=0$ (impossible). Therefore $x=1$.

Similarly, if $y>2$ then $\lambda_2=0$ and stationarity forces $2y=0$ (impossible). Therefore $y=2$.

Then multipliers come from stationarity:
\[
\lambda_1=2x=2\ge 0,\qquad \lambda_2=2y=4\ge 0.
\]

\textbf{Conclusion:} Minimizer is $(1,2)$ with value $5$.
\end{frame}

\section{Economic Example: Utility Maximization}

\begin{frame}{Utility Maximization Problem}
\textbf{Utility:}
\[
u(x_1,x_2)=\ln x_1 + 2\ln x_2.
\]

\textbf{Constraints:}
\[
p_1 x_1 + p_2 x_2 \le b,\qquad x_1\ge 0,\; x_2\ge 0,\qquad p_1,p_2>0.
\]

\textbf{Important domain note:} $\ln x$ is defined only for $x>0$, so effectively we optimize over $x_1>0,\;x_2>0$.
We assume $b>0$ so feasible positive bundles exist.
\end{frame}

\begin{frame}{(a) Lagrangian and Stationary Points}
Write the constraints in KKT form:
\[
g_0(x)=p_1x_1+p_2x_2-b\le 0,\qquad g_1(x)=-x_1\le 0,\qquad g_2(x)=-x_2\le 0.
\]

\textbf{Lagrangian:}
\[
\mathcal{L}(x_1,x_2,\lambda,\mu_1,\mu_2)=\ln x_1+2\ln x_2-\lambda(p_1x_1+p_2x_2-b)-\mu_1 x_1-\mu_2 x_2,
\]
with $\lambda,\mu_1,\mu_2\ge 0$.

\textbf{Stationarity (where defined):}
\[
\frac{\partial \mathcal{L}}{\partial x_1}=\frac{1}{x_1}-\lambda p_1-\mu_1=0,\qquad
\frac{\partial \mathcal{L}}{\partial x_2}=\frac{2}{x_2}-\lambda p_2-\mu_2=0.
\]
\end{frame}

\begin{frame}{(a) Stationary Point: Why It Must Be Interior}
Recall $u(x_1,x_2)=\ln x_1+2\ln x_2$.

Because $u$ is \textbf{strictly increasing} in each good on $(0,\infty)^2$:
\[
\frac{\partial u}{\partial x_1}=\frac{1}{x_1}>0,\qquad \frac{\partial u}{\partial x_2}=\frac{2}{x_2}>0,
\]
any maximizer must satisfy:
\begin{itemize}
\item \textbf{Budget binds}: $p_1x_1+p_2x_2=b$ (otherwise increase some $x_i$).
\item \textbf{Nonnegativity is slack}: $x_1>0,\;x_2>0$ so $\mu_1=\mu_2=0$.
\end{itemize}

So stationarity simplifies to
\[
\frac{1}{x_1}=\lambda p_1,\qquad \frac{2}{x_2}=\lambda p_2.
\]
\end{frame}

\begin{frame}{(a) Solve the Stationary Point}
From stationarity:
\[
x_1=\frac{1}{\lambda p_1},\qquad x_2=\frac{2}{\lambda p_2}.
\]

Use the binding budget constraint:
\[
p_1x_1+p_2x_2=b
\Rightarrow
p_1\frac{1}{\lambda p_1}+p_2\frac{2}{\lambda p_2}=b
\Rightarrow
\frac{1}{\lambda}+\frac{2}{\lambda}=b
\Rightarrow
\lambda=\frac{3}{b}.
\]

Therefore the (candidate) stationary point is
\[
x_1^\star=\frac{b}{3p_1},\qquad x_2^\star=\frac{2b}{3p_2}.
\]
\end{frame}

\begin{frame}{(b) Global Maximum: Argue, Then Conclude}
\textbf{Why this is the global maximum (not just a critical point):}
\begin{itemize}
\item $u(x_1,x_2)=\ln x_1+2\ln x_2$ is \textbf{strictly concave} on $(0,\infty)^2$.
\item The feasible set $\{(x_1,x_2): p_1x_1+p_2x_2\le b,\ x_1,x_2\ge 0\}$ is convex.
\item Maximizing a strictly concave function over a convex set gives a \textbf{unique global maximizer}.
\end{itemize}

So $\left(\frac{b}{3p_1},\frac{2b}{3p_2}\right)$ is the unique global maximum.

\textbf{Corresponding multipliers:}
\[
\lambda^\star=\frac{3}{b},\qquad \mu_1^\star=\mu_2^\star=0.
\]
\end{frame}

\begin{frame}{(b) Global Minimum and Other Local Extrema}
\textbf{There is no global minimum.}

Reason: along feasible sequences approaching the boundary (still satisfying the budget), utility goes to $-\infty$.
For example, fix any $\varepsilon>0$ and take
\[
x_1=\varepsilon,\qquad x_2=\frac{b-p_1\varepsilon}{p_2}>0.
\]
Then
\[
u(x_1,x_2)=\ln \varepsilon + 2\ln\left(\frac{b-p_1\varepsilon}{p_2}\right) \to -\infty \quad \text{as } \varepsilon\to 0^+.
\]
So the infimum is $-\infty$ and it is not attained.

\textbf{Other local extrema?} No. Strict concavity implies the maximizer is unique and there are no other local maxima; and since the objective is unbounded below, there is no local minimum in the feasible interior.
\end{frame}

\section{Extreme Value Theorem}

\begin{frame}{Extreme Value Theorem (EVT)}
\textbf{Theorem (Weierstrass / Extreme Value Theorem):}
If $f$ is \textbf{continuous} and $S\subset\R^n$ is \textbf{compact}, then there exist points $x_{\min},x_{\max}\in S$ such that
\[
f(x_{\min}) \le f(x) \le f(x_{\max}) \quad \text{for all } x\in S.
\]

\textbf{So:} a continuous function attains both a global minimum and a global maximum on a compact set.

\textbf{Key definition (in $\R^n$):} compact $\iff$ \textbf{closed and bounded}.
\end{frame}

\begin{frame}{Why EVT Matters in Optimization}
EVT is an \textbf{existence theorem}.

\begin{itemize}
\item KKT / Lagrange multipliers help you find \emph{candidates} for optima.
\item EVT helps you answer: \emph{Does an optimum exist at all?}
\end{itemize}

Typical workflow for constrained optimization:
\begin{enumerate}
\item Check whether the feasible set $S$ is compact (closed + bounded).
\item Check whether the objective is continuous on $S$.
\item If yes, EVT guarantees global min and max exist.
\item Then use calculus/KKT to find them.
\end{enumerate}
\end{frame}

\begin{frame}{EVT Example (Optima Exist)}
\textbf{Example:}
\[
\min_{x\in[-1,2]} x^2,\qquad \max_{x\in[-1,2]} x^2.
\]
Here $f(x)=x^2$ is continuous and $[-1,2]$ is compact, so both extrema exist.

\textbf{Compute:}
\begin{itemize}
\item Minimum at $x=0$ with value $0$.
\item Maximum at an endpoint: $\max\{(-1)^2,2^2\}=4$ achieved at $x=2$.
\end{itemize}
\end{frame}

\begin{frame}{EVT Counterexamples (Why Conditions Matter)}
\textbf{1) Set not closed:}
On $S=(0,1)$, $f(x)=x$ is continuous but the minimum is not attained (infimum $0$).

\vspace{0.3cm}
\textbf{2) Set not bounded:}
On $S=\R$, $f(x)=x^2$ attains a minimum (at $0$) but has no maximum.

\vspace{0.3cm}
\textbf{3) Objective not continuous on the feasible set:}
Even if $S$ is compact, discontinuities can break existence of extrema.
\end{frame}

\begin{frame}{Connection to the Utility Example}
The budget set $\{(x_1,x_2): p_1x_1+p_2x_2\le b,\ x_1,x_2\ge 0\}$ is \textbf{compact} (closed + bounded).

But $u(x_1,x_2)=\ln x_1+2\ln x_2$ is only defined (and continuous) on $x_1>0,\ x_2>0$, and it goes to $-\infty$ as $x_1\to 0^+$ or $x_2\to 0^+$.

\textbf{Therefore:}
\begin{itemize}
\item A maximum exists (and is unique) due to concavity and monotonicity.
\item A minimum does not exist because the utility is unbounded below near the boundary.
\end{itemize}
\end{frame}

\section{Summary}

\begin{frame}{Summary}
\begin{itemize}
\item \textbf{Unconstrained:} local minima satisfy $\grad f=0$; Hessian helps classify.
\item \textbf{Equality constraints:} solve $\grad_x \mathcal{L}=0$ with $h(x)=0$.
\item \textbf{Inequality constraints:} KKT adds $\lambda\ge 0$ and $\lambda_i g_i=0$.
\item \textbf{Active constraints matter:} only tight inequalities influence stationarity.
\end{itemize}
\end{frame}

\begin{frame}{Quick Practice Problems}
Try these after the lecture:
\begin{enumerate}
\item Minimize $x^2+y^2$ subject to $x-2y=0$.
\item Minimize $(x-1)^2$ subject to $x\le 0$.
\item Minimize $x^2+y^2$ subject to $x+y\ge 1$.
\end{enumerate}
\end{frame}

\end{document}
