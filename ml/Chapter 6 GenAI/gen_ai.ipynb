{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ad6de3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary and Best Practices\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **OpenAI API**: Powerful for text generation, function calling, and embeddings\n",
    "2. **Image Generation**: Use DALL-E or Stable Diffusion for creating images from text\n",
    "3. **Word Embeddings**: Convert text to vectors for semantic understanding\n",
    "4. **RAG**: Combine retrieval with generation for accurate, context-aware responses\n",
    "5. **Weaviate**: Scalable vector database with built-in RAG capabilities\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### Security\n",
    "- Never hardcode API keys\n",
    "- Use environment variables or secret management systems\n",
    "- Implement rate limiting and usage monitoring\n",
    "\n",
    "### Performance\n",
    "- Cache embeddings to avoid redundant API calls\n",
    "- Batch API requests when possible\n",
    "- Use streaming for real-time applications\n",
    "\n",
    "### RAG Optimization\n",
    "- Chunk documents appropriately (500-1000 tokens)\n",
    "- Use hybrid search for better retrieval\n",
    "- Implement re-ranking for improved relevance\n",
    "- Add metadata for filtering\n",
    "\n",
    "### Cost Management\n",
    "- Choose appropriate models (GPT-3.5 vs GPT-4)\n",
    "- Monitor token usage\n",
    "- Use smaller embedding models when possible\n",
    "- Implement caching strategies\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [OpenAI Documentation](https://platform.openai.com/docs)\n",
    "- [Weaviate Documentation](https://weaviate.io/developers/weaviate)\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Learning! ðŸš€**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b607c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete RAG system using Weaviate with functions\n",
    "\n",
    "def weaviate_rag_ask(client, question, collection_name=\"Article\", num_results=3):\n",
    "    \"\"\"\n",
    "    Ask a question and get an answer with sources using Weaviate\n",
    "    \n",
    "    Args:\n",
    "        client: Weaviate client instance\n",
    "        question: The question to ask\n",
    "        collection_name: Name of the collection to search\n",
    "        num_results: Number of relevant documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'answer' and 'sources'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        articles = client.collections.get(collection_name)\n",
    "        \n",
    "        # Perform generative search\n",
    "        response = articles.generate.near_text(\n",
    "            query=question,\n",
    "            limit=num_results,\n",
    "            grouped_task=f\"Answer this question: {question}\\n\\nBased on the following articles, provide a comprehensive answer. Cite specific information from the articles.\"\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'answer': response.generated,\n",
    "            'sources': []\n",
    "        }\n",
    "        \n",
    "        for item in response.objects:\n",
    "            result['sources'].append({\n",
    "                'title': item.properties.get('title', 'N/A'),\n",
    "                'category': item.properties.get('category', 'N/A'),\n",
    "                'content': item.properties.get('content', '')[:200] + '...'\n",
    "            })\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'answer': f\"Error: {e}\",\n",
    "            'sources': []\n",
    "        }\n",
    "\n",
    "# Usage example (requires Weaviate instance)\n",
    "\"\"\"\n",
    "result = weaviate_rag_ask(client, \"What is machine learning and how does it work?\")\n",
    "\n",
    "print(f\"Question: What is machine learning and how does it work?\\n\")\n",
    "print(f\"Answer: {result['answer']}\\n\")\n",
    "print(\"Sources:\")\n",
    "for i, source in enumerate(result['sources'], 1):\n",
    "    print(f\"{i}. {source['title']} ({source['category']})\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Weaviate RAG function created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a44f5d",
   "metadata": {},
   "source": [
    "## 5.10 Complete RAG with Weaviate\n",
    "\n",
    "Building a complete RAG application using functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab33ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "\"\"\"\n",
    "from weaviate.classes.query import Filter\n",
    "\n",
    "# Search with filter\n",
    "response = articles.query.near_text(\n",
    "    query=\"programming\",\n",
    "    limit=5,\n",
    "    filters=Filter.by_property(\"category\").equal(\"Programming\"),\n",
    "    return_properties=[\"title\", \"category\"]\n",
    ")\n",
    "\n",
    "print(\"Filtered Search Results:\")\n",
    "for item in response.objects:\n",
    "    print(f\"- {item.properties['title']} ({item.properties['category']})\")\n",
    "\"\"\"\n",
    "\n",
    "# Aggregations\n",
    "\"\"\"\n",
    "# Count objects by category\n",
    "response = articles.aggregate.over_all(\n",
    "    group_by=\"category\"\n",
    ")\n",
    "\n",
    "print(\"\\nArticles by Category:\")\n",
    "for group in response.groups:\n",
    "    print(f\"{group.grouped_by.value}: {group.total_count}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Filtering and aggregation examples provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b97810b",
   "metadata": {},
   "source": [
    "## 5.9 Filtering and Aggregations\n",
    "\n",
    "Apply filters and perform aggregations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af2ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative search - RAG with Weaviate\n",
    "\"\"\"\n",
    "response = articles.generate.near_text(\n",
    "    query=\"machine learning\",\n",
    "    limit=2,\n",
    "    single_prompt=\"Explain this article in simple terms: {content}\"\n",
    ")\n",
    "\n",
    "print(\"Generative Search Results (RAG):\")\n",
    "print(\"=\" * 70)\n",
    "for item in response.objects:\n",
    "    print(f\"\\nTitle: {item.properties['title']}\")\n",
    "    print(f\"Generated Summary: {item.generated}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Generative search example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd014a2",
   "metadata": {},
   "source": [
    "## 5.8 Generative Search (RAG with Weaviate)\n",
    "\n",
    "Use Weaviate's built-in RAG capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0765a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid search (combines keyword and vector search)\n",
    "\"\"\"\n",
    "from weaviate.classes.query import HybridFusion\n",
    "\n",
    "response = articles.query.hybrid(\n",
    "    query=\"Python programming\",\n",
    "    limit=2,\n",
    "    alpha=0.5,  # 0 = pure keyword, 1 = pure vector, 0.5 = balanced\n",
    "    fusion_type=HybridFusion.RELATIVE_SCORE,\n",
    "    return_properties=[\"title\", \"category\", \"content\"]\n",
    ")\n",
    "\n",
    "print(\"Hybrid Search Results:\")\n",
    "print(\"=\" * 70)\n",
    "for item in response.objects:\n",
    "    print(f\"\\nTitle: {item.properties['title']}\")\n",
    "    print(f\"Category: {item.properties['category']}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Hybrid search example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd70238b",
   "metadata": {},
   "source": [
    "## 5.7 Hybrid Search\n",
    "\n",
    "Combine keyword search with vector search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic search\n",
    "\"\"\"\n",
    "articles = client.collections.get(\"Article\")\n",
    "\n",
    "# Search for articles about AI and learning\n",
    "response = articles.query.near_text(\n",
    "    query=\"artificial intelligence and learning algorithms\",\n",
    "    limit=2,\n",
    "    return_properties=[\"title\", \"content\", \"category\"]\n",
    ")\n",
    "\n",
    "print(\"Search Results:\")\n",
    "print(\"=\" * 70)\n",
    "for item in response.objects:\n",
    "    print(f\"\\nTitle: {item.properties['title']}\")\n",
    "    print(f\"Category: {item.properties['category']}\")\n",
    "    print(f\"Content: {item.properties['content'][:100]}...\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Semantic search example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd63b994",
   "metadata": {},
   "source": [
    "## 5.6 Semantic Search\n",
    "\n",
    "Search for similar content using vector similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Sample articles\n",
    "sample_articles = [\n",
    "    {\n",
    "        \"title\": \"Introduction to Machine Learning\",\n",
    "        \"content\": \"Machine learning is a subset of artificial intelligence that focuses on building systems that can learn from data. It involves training algorithms on datasets to make predictions or decisions without being explicitly programmed.\",\n",
    "        \"category\": \"AI\",\n",
    "        \"published_date\": datetime(2024, 1, 15).isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Understanding Neural Networks\",\n",
    "        \"content\": \"Neural networks are computational models inspired by the human brain. They consist of layers of interconnected nodes that process information and learn patterns from data through training.\",\n",
    "        \"category\": \"Deep Learning\",\n",
    "        \"published_date\": datetime(2024, 2, 20).isoformat()\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Python Programming Best Practices\",\n",
    "        \"content\": \"Python is known for its readability and simplicity. Following PEP 8 style guide, writing docstrings, and using type hints are essential practices for maintainable code.\",\n",
    "        \"category\": \"Programming\",\n",
    "        \"published_date\": datetime(2024, 3, 10).isoformat()\n",
    "    }\n",
    "]\n",
    "\n",
    "# Insert data\n",
    "\"\"\"\n",
    "articles = client.collections.get(\"Article\")\n",
    "\n",
    "for article in sample_articles:\n",
    "    articles.data.insert(\n",
    "        properties=article\n",
    "    )\n",
    "print(f\"Inserted {len(sample_articles)} articles\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Data insertion example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334335c2",
   "metadata": {},
   "source": [
    "## 5.5 Adding Data\n",
    "\n",
    "Insert data into your Weaviate collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, Property, DataType\n",
    "\n",
    "# Create a collection for articles\n",
    "\"\"\"\n",
    "try:\n",
    "    # Delete collection if it exists\n",
    "    if client.collections.exists(\"Article\"):\n",
    "        client.collections.delete(\"Article\")\n",
    "    \n",
    "    # Create new collection\n",
    "    articles = client.collections.create(\n",
    "        name=\"Article\",\n",
    "        properties=[\n",
    "            Property(\n",
    "                name=\"title\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Title of the article\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"content\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Content of the article\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"category\",\n",
    "                data_type=DataType.TEXT,\n",
    "                description=\"Category of the article\"\n",
    "            ),\n",
    "            Property(\n",
    "                name=\"published_date\",\n",
    "                data_type=DataType.DATE,\n",
    "                description=\"Publication date\"\n",
    "            )\n",
    "        ],\n",
    "        # Configure vectorizer (use OpenAI embeddings)\n",
    "        vectorizer_config=Configure.Vectorizer.text2vec_openai(),\n",
    "        # Configure generative module (use OpenAI for generation)\n",
    "        generative_config=Configure.Generative.openai()\n",
    "    )\n",
    "    print(\"Collection 'Article' created successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating collection: {e}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Schema creation example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5d3195",
   "metadata": {},
   "source": [
    "## 5.4 Creating a Schema\n",
    "\n",
    "Define a collection (class) to store your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c477f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "\n",
    "# Connect to Weaviate Cloud Services\n",
    "\"\"\"\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=\"your-cluster-url.weaviate.network\",\n",
    "    auth_credentials=Auth.api_key(\"your-api-key\"),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n",
    "    }\n",
    ")\n",
    "print(\"Connected to Weaviate!\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Weaviate connection example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9474cc2c",
   "metadata": {},
   "source": [
    "## 5.3 Connecting to Weaviate\n",
    "\n",
    "You can use Weaviate Cloud Services (WCS):\n",
    "\n",
    "To get started, sign up at [Weaviate Cloud Services](https://console.weaviate.cloud/) for a free cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7154e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Weaviate client\n",
    "# !pip install weaviate-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc32b3f",
   "metadata": {},
   "source": [
    "## 5.2 Installation and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4616a143",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 5. Weaviate Vector Database\n",
    "\n",
    "Weaviate is an open-source vector database designed for storing and searching embeddings at scale.\n",
    "\n",
    "## 5.1 What is Weaviate?\n",
    "\n",
    "- **Vector Database**: Stores high-dimensional vectors (embeddings)\n",
    "- **Semantic Search**: Find similar items using vector similarity\n",
    "- **Hybrid Search**: Combine keyword and vector search\n",
    "- **GraphQL API**: Query data using GraphQL\n",
    "- **Modules**: Built-in integrations with OpenAI, Cohere, Hugging Face, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain-openai chromadb\n",
    "\n",
    "\"\"\"\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Load and split documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "documents = [\"Your long documents here...\"]\n",
    "texts = text_splitter.create_documents(documents)\n",
    "\n",
    "# Create vector store\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "# Create RAG chain\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    ")\n",
    "\n",
    "# Ask questions\n",
    "response = qa_chain.invoke(\"Your question here\")\n",
    "print(response['result'])\n",
    "\"\"\"\n",
    "\n",
    "print(\"LangChain RAG example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3777a",
   "metadata": {},
   "source": [
    "## 4.4 Advanced RAG with LangChain\n",
    "\n",
    "LangChain provides powerful tools for building RAG applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question using the RAG system\n",
    "question = \"What is deep learning and how does it relate to neural networks?\"\n",
    "\n",
    "result = generate_rag_response(question, knowledge_base, document_embeddings)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nAnswer:\\n{result['answer']}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nSources:\")\n",
    "for i, source in enumerate(result['sources'], 1):\n",
    "    print(f\"{i}. (Score: {source['score']:.4f}) {source['document']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8127e7a",
   "metadata": {},
   "source": [
    "## 4.3 Using the RAG System\n",
    "\n",
    "Now let's ask questions using our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d3a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple RAG implementation using functions\n",
    "\n",
    "# Example knowledge base\n",
    "knowledge_base = [\n",
    "    \"Python was created by Guido van Rossum and first released in 1991. It emphasizes code readability with significant whitespace.\",\n",
    "    \"Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks. They consist of interconnected nodes (neurons) organized in layers.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to progressively extract higher-level features from raw input.\",\n",
    "    \"Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret and manipulate human language.\",\n",
    "    \"Computer vision is a field of AI that trains computers to interpret and understand the visual world using digital images and videos.\",\n",
    "    \"Reinforcement learning is an area of machine learning where an agent learns to make decisions by performing actions and receiving rewards or penalties.\"\n",
    "]\n",
    "\n",
    "# Index the documents (create embeddings)\n",
    "print(\"Indexing documents...\")\n",
    "document_embeddings = [get_embedding(doc) for doc in knowledge_base]\n",
    "print(f\"Indexed {len(knowledge_base)} documents\")\n",
    "\n",
    "def retrieve_documents(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieve most relevant documents for a query\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        documents: List of document texts\n",
    "        doc_embeddings: List of document embeddings\n",
    "        top_k: Number of top documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with 'document' and 'score'\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            'document': documents[idx],\n",
    "            'score': similarities[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def generate_rag_response(query, documents, doc_embeddings, top_k=3):\n",
    "    \"\"\"\n",
    "    Generate response using RAG approach\n",
    "    \n",
    "    Args:\n",
    "        query: User's question\n",
    "        documents: List of document texts\n",
    "        doc_embeddings: List of document embeddings\n",
    "        top_k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'answer' and 'sources'\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = retrieve_documents(query, documents, doc_embeddings, top_k)\n",
    "    \n",
    "    # Build context from retrieved documents\n",
    "    context = \"\\n\\n\".join([doc['document'] for doc in retrieved_docs])\n",
    "    \n",
    "    # Create augmented prompt\n",
    "    augmented_prompt = f\"\"\"Answer the question based on the context below.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context.\"},\n",
    "            {\"role\": \"user\", \"content\": augmented_prompt}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'answer': response.choices[0].message.content,\n",
    "        'sources': retrieved_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1714593",
   "metadata": {},
   "source": [
    "## 4.2 Simple RAG Implementation\n",
    "\n",
    "Let's build a basic RAG system using functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf8e941",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 4. RAG (Retrieval Augmented Generation)\n",
    "\n",
    "RAG combines retrieval systems with language models to provide accurate, context-aware responses.\n",
    "\n",
    "## 4.1 RAG Architecture\n",
    "\n",
    "1. **Index**: Store documents as embeddings in a vector database\n",
    "2. **Retrieve**: Find relevant documents for a query\n",
    "3. **Augment**: Add retrieved context to the prompt\n",
    "4. **Generate**: Use LLM to generate response with context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d310b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Sentence Transformers (Hugging Face)\n",
    "# !pip install sentence-transformers\n",
    "\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "sentences = ['This is a test sentence', 'This is another sentence']\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(f\"Shape: {embeddings.shape}\")\n",
    "print(f\"Embedding: {embeddings[0][:5]}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Sentence Transformers example provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8707f7",
   "metadata": {},
   "source": [
    "## 3.4 Other Embedding Models\n",
    "\n",
    "Beyond OpenAI, there are other popular embedding models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9322be2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document database\n",
    "documents = [\n",
    "    \"Python is a high-level programming language\",\n",
    "    \"Machine learning uses statistical techniques\",\n",
    "    \"Neural networks are inspired by the human brain\",\n",
    "    \"Data science involves analyzing large datasets\",\n",
    "    \"JavaScript is used for web development\",\n",
    "    \"Deep learning is a subset of machine learning\"\n",
    "]\n",
    "\n",
    "# Get embeddings for all documents\n",
    "doc_embeddings = [get_embedding(doc) for doc in documents]\n",
    "\n",
    "# Search query\n",
    "query = \"Tell me about AI and neural networks\"\n",
    "query_embedding = get_embedding(query)\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = cosine_similarity([query_embedding], doc_embeddings)[0]\n",
    "\n",
    "# Get top 3 results\n",
    "top_indices = np.argsort(similarities)[::-1][:3]\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Most relevant documents:\")\n",
    "for i, idx in enumerate(top_indices, 1):\n",
    "    print(f\"{i}. (Score: {similarities[idx]:.4f}) {documents[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62573edb",
   "metadata": {},
   "source": [
    "## 3.3 Semantic Search\n",
    "\n",
    "Find the most relevant documents for a query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between embeddings\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(\"Similarity Matrix:\")\n",
    "print(\"=\" * 70)\n",
    "for i, text1 in enumerate(texts):\n",
    "    print(f\"\\n'{text1}':\")\n",
    "    for j, text2 in enumerate(texts):\n",
    "        if i != j:\n",
    "            print(f\"  vs '{text2}': {similarity_matrix[i][j]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37e463",
   "metadata": {},
   "source": [
    "## 3.2 Measuring Similarity\n",
    "\n",
    "Use cosine similarity to find how similar texts are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71fa6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Generate embeddings using OpenAI\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"Get embedding for a text string\"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"The cat sits on the mat\",\n",
    "    \"A feline rests on the rug\",\n",
    "    \"Dogs are loyal animals\",\n",
    "    \"Machine learning is fascinating\"\n",
    "]\n",
    "\n",
    "# Get embeddings\n",
    "embeddings = [get_embedding(text) for text in texts]\n",
    "\n",
    "print(f\"Embedding dimension: {len(embeddings[0])}\")\n",
    "print(f\"First few values of embedding 1: {embeddings[0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44da39bb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 3. Word Embeddings\n",
    "\n",
    "Word embeddings are dense vector representations of text that capture semantic meaning.\n",
    "\n",
    "## 3.1 Understanding Embeddings\n",
    "\n",
    "Embeddings convert text into numerical vectors where similar meanings have similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba49ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variation of an existing image\n",
    "\"\"\"\n",
    "# First, download and prepare your image\n",
    "response = client.images.create_variation(\n",
    "    image=open(\"path/to/image.png\", \"rb\"),\n",
    "    n=2,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "for idx, img_data in enumerate(response.data):\n",
    "    print(f\"Variation {idx + 1}: {img_data.url}\")\n",
    "\"\"\"\n",
    "\n",
    "# Image editing with mask\n",
    "\"\"\"\n",
    "response = client.images.edit(\n",
    "    model=\"dall-e-2\",\n",
    "    image=open(\"original.png\", \"rb\"),\n",
    "    mask=open(\"mask.png\", \"rb\"),\n",
    "    prompt=\"A sunlit indoor lounge with a pool\",\n",
    "    n=1,\n",
    "    size=\"1024x1024\"\n",
    ")\n",
    "\n",
    "print(f\"Edited image: {response.data[0].url}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Image editing examples provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e571d",
   "metadata": {},
   "source": [
    "## 2.3 Image Editing and Variations\n",
    "\n",
    "Edit existing images or create variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e21f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stability-sdk\n",
    "\n",
    "# Example using Stability AI API\n",
    "\"\"\"\n",
    "import requests\n",
    "\n",
    "API_KEY = os.getenv(\"STABILITY_API_KEY\")\n",
    "\n",
    "response = requests.post(\n",
    "    \"https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image\",\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "    },\n",
    "    json={\n",
    "        \"text_prompts\": [\n",
    "            {\n",
    "                \"text\": \"A futuristic cityscape with flying cars\",\n",
    "                \"weight\": 1\n",
    "            }\n",
    "        ],\n",
    "        \"cfg_scale\": 7,\n",
    "        \"height\": 1024,\n",
    "        \"width\": 1024,\n",
    "        \"samples\": 1,\n",
    "        \"steps\": 30,\n",
    "    },\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Process image data\n",
    "    print(\"Image generated successfully!\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Stability AI example code provided above (commented out)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2742d",
   "metadata": {},
   "source": [
    "## 2.2 Stability AI (Stable Diffusion)\n",
    "\n",
    "Alternative image generation API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a753ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an image with DALL-E\n",
    "response = client.images.generate(\n",
    "    model=\"dall-e-3\",\n",
    "    prompt=\"A serene mountain landscape at sunset, with a lake reflecting the colorful sky, digital art style\",\n",
    "    size=\"1024x1024\",\n",
    "    quality=\"standard\",\n",
    "    n=1\n",
    ")\n",
    "\n",
    "image_url = response.data[0].url\n",
    "print(f\"Generated image URL: {image_url}\")\n",
    "\n",
    "# Display the image\n",
    "from IPython.display import Image, display\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d7dab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 2. Image Generation APIs\n",
    "\n",
    "## 2.1 OpenAI DALL-E\n",
    "\n",
    "Generate images from text descriptions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b2ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define a function\n",
    "def get_weather(location, unit=\"celsius\"):\n",
    "    \"\"\"Get the current weather for a location\"\"\"\n",
    "    # This is a mock function\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": 22,\n",
    "        \"unit\": unit,\n",
    "        \"description\": \"Sunny\"\n",
    "    }\n",
    "\n",
    "# Define function schema for OpenAI\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Make a request that should trigger function calling\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like in Paris?\"}\n",
    "    ],\n",
    "    functions=functions,\n",
    "    function_call=\"auto\"\n",
    ")\n",
    "\n",
    "message = response.choices[0].message\n",
    "\n",
    "if message.function_call:\n",
    "    function_name = message.function_call.name\n",
    "    function_args = json.loads(message.function_call.arguments)\n",
    "    \n",
    "    print(f\"AI wants to call: {function_name}\")\n",
    "    print(f\"With arguments: {function_args}\")\n",
    "    \n",
    "    # Execute the function\n",
    "    if function_name == \"get_weather\":\n",
    "        result = get_weather(**function_args)\n",
    "        print(f\"\\nFunction result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cba65f",
   "metadata": {},
   "source": [
    "## 1.3 Function Calling\n",
    "\n",
    "Allow the AI to call functions with structured outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b92320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming response\n",
    "print(\"Streaming response:\")\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about Python programming.\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c1e32d",
   "metadata": {},
   "source": [
    "## 1.2 Streaming Responses\n",
    "\n",
    "For real-time responses (useful for chatbots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic chat completion\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that explains complex topics simply.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain machine learning in 2 sentences.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "print(\"AI Response:\")\n",
    "print(response.choices[0].message.content)\n",
    "print(f\"\\nTokens used: {response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a683f",
   "metadata": {},
   "source": [
    "## 1.1 Chat Completions\n",
    "\n",
    "The most common use case - having a conversation with the AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23da2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "print(\"OpenAI client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a124bdd",
   "metadata": {},
   "source": [
    "## Basic Setup\n",
    "\n",
    "Store your API key in a `.env` file (never commit this to version control!):\n",
    "```\n",
    "OPENAI_API_KEY=your-api-key-here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647cbb8",
   "metadata": {},
   "source": [
    "# 1. Using OpenAI API\n",
    "\n",
    "The OpenAI API provides access to powerful language models like GPT-4, GPT-3.5, and more.\n",
    "\n",
    "## Installation and Setup\n",
    "\n",
    "First, install the OpenAI Python library:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a4d7f",
   "metadata": {},
   "source": [
    "# Generative AI Tutorial\n",
    "\n",
    "This comprehensive tutorial covers essential GenAI technologies and tools:\n",
    "1. OpenAI API\n",
    "2. Image Generation APIs\n",
    "3. Word Embeddings\n",
    "4. RAG (Retrieval Augmented Generation)\n",
    "5. Weaviate Vector Database\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
