{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"## Title\"\n",
    "lightbox: true\n",
    "format: \n",
    "  html:\n",
    "    code-fold: false\n",
    "number-offset: 1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238.178\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# === Parameters ===\n",
    "N_total = 800\n",
    "N_f = 16\n",
    "m = 4294967296\n",
    "a_lcg = 1664525\n",
    "c_lcg = 1013904223\n",
    "s0 = 314159265\n",
    "mu = [5.0, 10.0, 3.0, 8.0, 15.0, 6.0, 12.0, 7.0, 20.0, 25.0, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0]\n",
    "sigma = [2.0, 3.0, 1.5, 2.5, 4.0, 2.0, 3.5, 2.0, 3.0, 4.0, 2.0, 3.0, 5.0, 2.5, 3.0, 4.0]\n",
    "delta = [2.5, -3.0, 2.0, -2.0, 3.5, -1.5, 2.0, -2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "default_rate = 0.30\n",
    "N_sel = 6\n",
    "train_frac = 0.70\n",
    "T_iter = 20\n",
    "lam = 0.01\n",
    "\n",
    "# === Stage 1: Synthetic borrower generation via LCG + Box-Muller ===\n",
    "state = s0\n",
    "def lcg_next():\n",
    "    global state\n",
    "    u = state / m\n",
    "    state = (a_lcg * state + c_lcg) % m\n",
    "    return u\n",
    "\n",
    "labels = [0] * N_total\n",
    "features = [[0.0] * N_f for _ in range(N_total)]\n",
    "\n",
    "for i in range(N_total):\n",
    "    u_label = lcg_next()\n",
    "    labels[i] = 1 if u_label < default_rate else 0\n",
    "    for pair in range(0, N_f, 2):\n",
    "        j1, j2 = pair, pair + 1\n",
    "        u1 = lcg_next()\n",
    "        u2 = lcg_next()\n",
    "        u1 = max(u1, 1e-15)\n",
    "        r = math.sqrt(-2.0 * math.log(u1))\n",
    "        z1 = r * math.cos(2.0 * math.pi * u2)\n",
    "        z2 = r * math.sin(2.0 * math.pi * u2)\n",
    "        features[i][j1] = mu[j1] + delta[j1] * labels[i] + sigma[j1] * z1\n",
    "        features[i][j2] = mu[j2] + delta[j2] * labels[i] + sigma[j2] * z2\n",
    "\n",
    "# === Stage 2: Fisher discriminant feature selection ===\n",
    "fisher_scores = []\n",
    "for j in range(N_f):\n",
    "    vals_0, vals_1 = [], []\n",
    "    for i in range(N_total):\n",
    "        (vals_1 if labels[i] == 1 else vals_0).append(features[i][j])\n",
    "    n0, n1 = len(vals_0), len(vals_1)\n",
    "    # Two-pass: mean then variance, left-to-right\n",
    "    sum0 = 0.0\n",
    "    for v in vals_0: sum0 += v\n",
    "    mu0j = sum0 / n0\n",
    "    sum1 = 0.0\n",
    "    for v in vals_1: sum1 += v\n",
    "    mu1j = sum1 / n1\n",
    "    var0 = 0.0\n",
    "    for v in vals_0: var0 += (v - mu0j) ** 2\n",
    "    var0 /= n0\n",
    "    var1 = 0.0\n",
    "    for v in vals_1: var1 += (v - mu1j) ** 2\n",
    "    var1 /= n1\n",
    "    denom = var0 + var1\n",
    "    if denom < 1e-15: denom = 1e-15\n",
    "    fisher_scores.append((-(mu1j - mu0j) ** 2 / denom, j))\n",
    "\n",
    "fisher_scores.sort(key=lambda x: (x[0], x[1]))\n",
    "selected_indices = sorted([fisher_scores[k][1] for k in range(N_sel)])\n",
    "\n",
    "# === Stage 3: Train/test split ===\n",
    "n_train = int(math.floor(N_total * train_frac))\n",
    "n_test = N_total - n_train\n",
    "train_X = [[features[i][j] for j in selected_indices] for i in range(n_train)]\n",
    "train_y = labels[:n_train]\n",
    "test_X = [[features[i][j] for j in selected_indices] for i in range(n_train, N_total)]\n",
    "test_y = labels[n_train:]\n",
    "\n",
    "# === Stage 4: Standardization using training statistics ===\n",
    "train_means = []\n",
    "train_stds = []\n",
    "for col in range(N_sel):\n",
    "    s = 0.0\n",
    "    for i in range(n_train): s += train_X[i][col]\n",
    "    mean_j = s / n_train\n",
    "    s2 = 0.0\n",
    "    for i in range(n_train): s2 += (train_X[i][col] - mean_j) ** 2\n",
    "    std_j = math.sqrt(s2 / n_train)\n",
    "    if std_j < 1e-10: std_j = 1e-10\n",
    "    train_means.append(mean_j)\n",
    "    train_stds.append(std_j)\n",
    "\n",
    "for i in range(n_train):\n",
    "    for col in range(N_sel):\n",
    "        train_X[i][col] = (train_X[i][col] - train_means[col]) / train_stds[col]\n",
    "for i in range(n_test):\n",
    "    for col in range(N_sel):\n",
    "        test_X[i][col] = (test_X[i][col] - train_means[col]) / train_stds[col]\n",
    "\n",
    "# === Stage 5: Logistic regression via Newton-Raphson ===\n",
    "X_train = [[1.0] + train_X[i] for i in range(n_train)]\n",
    "d = N_sel + 1\n",
    "beta = [0.0] * d\n",
    "\n",
    "for t in range(T_iter):\n",
    "    # (a) Linear predictor\n",
    "    eta = []\n",
    "    for i in range(n_train):\n",
    "        s = 0.0\n",
    "        for j in range(d): s += X_train[i][j] * beta[j]\n",
    "        eta.append(s)\n",
    "    # (b) Predicted probabilities, clamped\n",
    "    p = []\n",
    "    for i in range(n_train):\n",
    "        pi = 1.0 / (1.0 + math.exp(-eta[i]))\n",
    "        p.append(max(1e-12, min(1.0 - 1e-12, pi)))\n",
    "    # (c) Weights\n",
    "    w = [p[i] * (1.0 - p[i]) for i in range(n_train)]\n",
    "    # (d) Hessian + regularization\n",
    "    H = [[0.0] * d for _ in range(d)]\n",
    "    for j1 in range(d):\n",
    "        for j2 in range(d):\n",
    "            s = 0.0\n",
    "            for i in range(n_train): s += w[i] * X_train[i][j1] * X_train[i][j2]\n",
    "            H[j1][j2] = s\n",
    "    for j in range(1, d): H[j][j] += lam\n",
    "    # (e) Gradient + regularization\n",
    "    g = [0.0] * d\n",
    "    for j in range(d):\n",
    "        s = 0.0\n",
    "        for i in range(n_train): s += X_train[i][j] * (train_y[i] - p[i])\n",
    "        g[j] = s\n",
    "    for j in range(1, d): g[j] -= lam * beta[j]\n",
    "    # (f) Solve H * delta = g via LU with partial pivoting (Doolittle)\n",
    "    A = [row[:] for row in H]\n",
    "    b = g[:]\n",
    "    for k in range(d):\n",
    "        max_val, max_row = abs(A[k][k]), k\n",
    "        for row in range(k + 1, d):\n",
    "            if abs(A[row][k]) > max_val:\n",
    "                max_val = abs(A[row][k])\n",
    "                max_row = row\n",
    "        if max_row != k:\n",
    "            A[k], A[max_row] = A[max_row], A[k]\n",
    "            b[k], b[max_row] = b[max_row], b[k]\n",
    "        for row in range(k + 1, d):\n",
    "            factor = A[row][k] / A[k][k]\n",
    "            A[row][k] = factor\n",
    "            for col in range(k + 1, d): A[row][col] -= factor * A[k][col]\n",
    "            b[row] -= factor * b[k]\n",
    "    delta_beta = [0.0] * d\n",
    "    for i in range(d - 1, -1, -1):\n",
    "        s = b[i]\n",
    "        for j in range(i + 1, d): s -= A[i][j] * delta_beta[j]\n",
    "        delta_beta[i] = s / A[i][i]\n",
    "    for j in range(d): beta[j] += delta_beta[j]\n",
    "\n",
    "# === Stage 6: Test prediction ===\n",
    "X_test = [[1.0] + test_X[i] for i in range(n_test)]\n",
    "test_p = []\n",
    "test_pred = []\n",
    "for i in range(n_test):\n",
    "    s = 0.0\n",
    "    for j in range(d): s += X_test[i][j] * beta[j]\n",
    "    pi = 1.0 / (1.0 + math.exp(-s))\n",
    "    pi = max(1e-12, min(1.0 - 1e-12, pi))\n",
    "    test_p.append(pi)\n",
    "    test_pred.append(1 if pi >= 0.5 else 0)\n",
    "\n",
    "# === Stage 7: Evaluation ===\n",
    "# Log-loss\n",
    "logloss = 0.0\n",
    "for i in range(n_test):\n",
    "    logloss += test_y[i] * math.log(test_p[i]) + (1.0 - test_y[i]) * math.log(1.0 - test_p[i])\n",
    "logloss = -logloss / n_test\n",
    "\n",
    "# Balanced accuracy\n",
    "TP = FP = TN = FN = 0\n",
    "for i in range(n_test):\n",
    "    if test_y[i] == 1 and test_pred[i] == 1: TP += 1\n",
    "    elif test_y[i] == 0 and test_pred[i] == 1: FP += 1\n",
    "    elif test_y[i] == 0 and test_pred[i] == 0: TN += 1\n",
    "    else: FN += 1\n",
    "sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "specificity = TN / (TN + FP) if (TN + FP) > 0 else 0.0\n",
    "BA = (sensitivity + specificity) / 2.0\n",
    "\n",
    "# Coefficient L2 norm\n",
    "beta_norm_sq = 0.0\n",
    "for j in range(d): beta_norm_sq += beta[j] ** 2\n",
    "beta_norm = math.sqrt(beta_norm_sq)\n",
    "\n",
    "# Output\n",
    "T_out = 1e3 * logloss + 1e2 * (1.0 - BA) + beta_norm + N_sel\n",
    "print(round(T_out, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "![image.png](../background_photos/)\n",
    "[’¨’∏÷Ç’Ω’°’∂’Ø’°÷Ä’´ ’∞’≤’∏÷Ç’¥’®](https://unsplash.com/photos/a-large-mountain-with-a-very-tall-cliff-UiP9KfVe3aQ), ’Ä’•’≤’´’∂’°’Ø’ù []()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<a href=\"ToDo\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> (ToDo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "> Song reference - ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üé¶ ’è’•’Ω’°’§’°’Ω’•÷Ä + ’¨÷Ä’°÷Å’∏÷Ç÷Å’´’π (ToDo)\n",
    "\n",
    "ToDo\n",
    "1. [’è’•’Ω’∏÷Ç’©’µ’∏÷Ç’∂ 2025](https://youtu.be/TIWU_bjFuUc) \\\n",
    "2. [’è’•’Ω’∏÷Ç’©’µ’∏÷Ç’∂ 2023 (ToDo)]()  \\\n",
    "3. [‘≥’∏÷Ä’Æ’∂’°’Ø’°’∂ 2025](https://youtu.be/zf8xEfdLXRo) \\\n",
    "4. [‘≥’∏÷Ä’Æ’∂’°’Ø’°’∂ 2023 (ToDo)]()  \\\n",
    "5. [’à÷Ä’∏’∑ ’ø’∂’°’µ’´’∂’∂’•÷Ä’´ ’¨’∏÷Ç’Æ’∏÷Ç’¥’∂’•÷Ä (ToDo)]()\n",
    "    \n",
    "Google Forms ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìö ’Ü’µ’∏÷Ç’©’®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è ‘≥’∏÷Ä’Æ’∂’°’Ø’°’∂\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üè°’è’∂’°’µ’´’∂\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé≤ 00\n",
    "- ‚ñ∂Ô∏è[Video]()\n",
    "- ‚ñ∂Ô∏è[Random link]()\n",
    "- üá¶üá≤üé∂[]()\n",
    "- üåêüé∂[]()\n",
    "- ü§å[‘ø’°÷Ä’£’´’∂]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfbUegKqXVyH"
   },
   "source": [
    "\n",
    "<a href=\"http://s01.flagcounter.com/more/1oO\"><img src=\"https://s01.flagcounter.com/count2/1oO/bg_FFFFFF/txt_000000/border_CCCCCC/columns_2/maxflags_10/viewers_0/labels_0/pageviews_1/flags_0/percent_0/\" alt=\"Flag Counter\"></a>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOx7X+DxNeKu1zUVVCmsSHJ",
   "provenance": [
    {
     "file_id": "1_9UtYmPVVGmnWIKdBzPYkbtTlTbd0clo",
     "timestamp": 1735604987843
    },
    {
     "file_id": "15x56uwwONMo_ilzUJgt6UcX1d552xH6X",
     "timestamp": 1708441161475
    },
    {
     "file_id": "1LbG88IWtk30WlIoINzG4_vXHoJAvoDaP",
     "timestamp": 1683614319950
    }
   ]
  },
  "kernelspec": {
   "display_name": "ma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
